{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to neural networks\n",
    "\n",
    "<img src=\"1.png\" width=\"500\" style=\"display: block; margin: 0 auto;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f$: activation function. We always use Sigmod function as the activation function.\n",
    "<img src=\"2.png\" width=\"250\" style=\"display: block; margin: 0 auto;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron\n",
    "\n",
    "If there are two layers of neurons, it is \"Perceptron\":\n",
    "\n",
    "This is a picture describing that two input in \"Perceptron\".\n",
    "<img src=\"3.png\" width=\"250\" style=\"display: block; margin: 0 auto;\" />\n",
    "At this time, we have:\n",
    "$$\n",
    "y=f(\\sum_iw_ix_i-\\theta)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters can be learned given by lots of training datas $(x_i, y_i)$.\n",
    "$$\n",
    "w_i\\leftarrow w_i+\\Delta w_i ,\\\\\\Delta w_i=\\eta(y-\\hat{y})x_i ,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BackPropagation(more layers than perceptron)\n",
    "\n",
    "Given data:\n",
    "$$\n",
    "D=\\{(x_1,y_1), (x_2,y_2), ..., (x_m,y_m)\\}, \\quad x_i\\in R^d, y_i\\in R^l\n",
    "$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
